{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os, shutil\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "import talos\n",
    "\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the datasets\n",
    "\n",
    "train_y = pickle.load(open(\"train_y.pkl\", \"rb\" ) )\n",
    "test_y = pickle.load(open(\"test_y.pkl\", \"rb\" ) )\n",
    "val_y = pickle.load(open(\"val_y.pkl\", \"rb\" ) )\n",
    "\n",
    "train_img = pickle.load(open(\"train_img.pkl\", \"rb\" ) )\n",
    "test_img = pickle.load(open(\"test_img.pkl\", \"rb\" ) )\n",
    "val_img = pickle.load(open(\"val_img.pkl\", \"rb\" ) )\n",
    "\n",
    "train_images = pickle.load(open(\"train_images.pkl\", \"rb\" ) )\n",
    "test_images = pickle.load(open(\"test_images.pkl\", \"rb\" ) )\n",
    "val_images = pickle.load(open(\"validate_images.pkl\", \"rb\" ) )\n",
    "\n",
    "train_labels = pickle.load(open(\"train_labels.pkl\", \"rb\" ) )\n",
    "test_labels = pickle.load(open(\"test_labels.pkl\", \"rb\" ) )\n",
    "val_labels = pickle.load(open(\"val_labels.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data with Stanford Dog Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our dataset has relatively few number of images per class, we'll combine the images we scraped with the \"Stanford Dog Dataset\" </http://vision.stanford.edu/aditya86/ImageNetDogs/>.\n",
    "\n",
    "After download, the folder names were cleaned to align with our existing data. We also removed any folders containing images for breeds not included in our original dataset. Furthermore, not all 50 breeds are included in the Stanford Dog Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds = ['Akitas','Australian Shepherds','Basset Hounds','Beagles','Belgian Malinois','Bernese Mountain',\n",
    "              'Bichons Frises','Bloodhounds','Border Collies','Boston Terriers','Boxers','Brittanys','Bulldogs',\n",
    "              'Cane Corso','Cavalier King Charles Spaniels','Chesapeake Bay Retrievers','Chihuahuas',\n",
    "              'Cocker Spaniels','Dachshunds','Dalmatians','Doberman Pinschers','English Cocker Spaniels',\n",
    "              'English Springer Spaniels','French Bulldogs','German Shepherd','German Shorthaired Pointers',\n",
    "              'Golden Retrievers','Great Danes','Havanese','Labrador Retrievers','Maltese','Mastiffs',\n",
    "              'Miniature American Shepherds','Miniature Schnauzers','Newfoundlands','Pembroke Welsh Corgis',\n",
    "              'Pomeranians','Poodles','Portuguese Water Dogs','Pugs','Rhodesian Ridgebacks','Rottweilers',\n",
    "              'Shetland Sheepdogs','Shiba Inu','Shih Tzu','Siberian Huskies','Vizslas','Weimaraners',\n",
    "              'West Highland White Terriers','Yorkshire Terriers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'split_data_with_stanford/'\n",
    "train = os.path.join(new_dir, 'train')\n",
    "test = os.path.join(new_dir, 'test')\n",
    "validate = os.path.join(new_dir, 'validate')\n",
    "\n",
    "os.mkdir(new_dir)\n",
    "os.mkdir(train)\n",
    "os.mkdir(test)\n",
    "os.mkdir(validate)\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    os.mkdir(os.path.join(train, breed))\n",
    "    os.mkdir(os.path.join(test, breed))\n",
    "    os.mkdir(os.path.join(validate, breed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will copy our Dog Image folder, create sub-folders for each breed and then combine the breed-specific folders\n",
    "\n",
    "new_dir = 'dog-images-by-breed/'\n",
    "os.mkdir(new_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37  breeds in common\n"
     ]
    }
   ],
   "source": [
    "#Limiting dog breeds to those available in both datasets\n",
    "\n",
    "stanford_dog_data = './stanford-dog-Images'\n",
    "\n",
    "dog_breeds = list(os.listdir(stanford_dog_data))\n",
    "print(len(dog_breeds), \" breeds in common\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make folders for each breed\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    os.mkdir(os.path.join(new_dir,breed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining images into destination folders\n",
    "\n",
    "destination_dir = './dog-images-by-breed/'\n",
    "original_data_dir = './Dog Images/'\n",
    "stanford_dog_data_dir = './stanford-dog-Images'\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    \n",
    "    count = 1\n",
    "    clean_breed = breed.replace(\" \",\"_\")\n",
    "    \n",
    "    #moving original data into new folders, filtering only for chosen breeds\n",
    "    \n",
    "    for file in os.listdir(original_data_dir):\n",
    "        if file.startswith(clean_breed+\"_\"):\n",
    "            path = original_data_dir+file\n",
    "            #defining destination so that the file is also re-named\n",
    "            dst = destination_dir+breed+\"/\"+clean_breed+ \"_\" + str(count)+\".png\"\n",
    "            copyfile(path, dst)\n",
    "            count += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    #moving stanford images into new folders\n",
    "    \n",
    "    count = len(os.listdir(destination_dir+'/'+breed)) + 1\n",
    "    \n",
    "    for file in os.listdir(stanford_dog_data_dir+'/'+breed):\n",
    "        \n",
    "        path = stanford_dog_data_dir+'/'+breed+'/'+file\n",
    "        #defining destination so that the file is also re-named\n",
    "        dst = destination_dir+breed+\"/\"+clean_breed+ \"_\" + str(count)+\".png\"\n",
    "        copyfile(path, dst)\n",
    "        count += 1\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = []\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    count = 0 \n",
    "    for file in os.listdir('./dog-images-by-breed/'+breed):\n",
    "        if file.startswith((breed.replace(\" \",\"_\"))):\n",
    "            count += 1\n",
    "        else: \n",
    "            pass\n",
    "    image_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_img_count_dict = dict(zip(dog_breeds, image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 images\n"
     ]
    }
   ],
   "source": [
    "#Determining the lowest number of images returned\n",
    "#will limit all breeds to use this number to prevent class imbalance\n",
    "\n",
    "lowest_img_count = min(breed_img_count_dict, key=breed_img_count_dict.get)\n",
    "print(str(breed_img_count_dict[lowest_img_count]) + \" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#629 is an increase from the original 478 images we were using previously\n",
    "\n",
    "#train, test, validate sizes\n",
    "\n",
    "#train = 377 ~60%\n",
    "#test = 94 ~15%\n",
    "#validate = 158 ~25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting images into sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_imgs_dir = './dog-images-by-breed/'\n",
    "\n",
    "destination = './split_data_with_stanford/'\n",
    "\n",
    "train_dir = './split_data_with_stanford/train'\n",
    "test_dir = './split_data_with_stanford/test'\n",
    "validate_dir = './split_data_with_stanford/validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for breed in dog_breeds:\n",
    "    \n",
    "    for file in sorted(os.listdir(combined_imgs_dir+breed))[:158]:\n",
    "        path = combined_imgs_dir+breed+'/'+file\n",
    "        dst = validate_dir+'/'+breed+'/'+file\n",
    "        copyfile(path, dst)\n",
    "        \n",
    "    for file in sorted(os.listdir(combined_imgs_dir+breed))[159:253]:\n",
    "        path = combined_imgs_dir+breed+'/'+file\n",
    "        dst = test_dir+'/'+breed+'/'+file\n",
    "        copyfile(path, dst)\n",
    "\n",
    "    for file in sorted(os.listdir(combined_imgs_dir+breed))[160:537]:\n",
    "        path = combined_imgs_dir+breed+'/'+file\n",
    "        dst = train_dir+'/'+breed+'/'+file\n",
    "        copyfile(path, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking counts & defining batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13949"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train expected \n",
    "\n",
    "37*377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13949\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    \n",
    "    for file in os.listdir(train_dir+'/'+breed):\n",
    "        count += 1\n",
    "\n",
    "train_batch_size = count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3478"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test expected \n",
    "\n",
    "37*94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    \n",
    "    for file in os.listdir(test_dir+'/'+breed):\n",
    "        count += 1\n",
    "\n",
    "test_batch_size = count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5846"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate expected \n",
    "\n",
    "37*158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5846\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for breed in dog_breeds:\n",
    "    \n",
    "    for file in os.listdir(validate_dir+'/'+breed):\n",
    "        count += 1\n",
    "\n",
    "validate_batch_size = count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3478 images belonging to 37 classes.\n",
      "Found 5846 images belonging to 37 classes.\n",
      "Found 13949 images belonging to 37 classes.\n"
     ]
    }
   ],
   "source": [
    "#resizing images\n",
    "\n",
    "#test\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir, \n",
    "        target_size=(150, 150), batch_size = test_batch_size) \n",
    "\n",
    "#validate\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        validate_dir, \n",
    "        target_size=(150, 150), batch_size = validate_batch_size)\n",
    "\n",
    "#train\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(150, 150), batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "validate_images, validate_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 13949\n",
      "Number of testing samples: 3478\n",
      "Number of validation samples: 5846\n",
      "train_images shape: (13949, 150, 150, 3)\n",
      "train_labels shape: (13949, 37)\n",
      "test_images shape: (3478, 150, 150, 3)\n",
      "test_labels shape: (3478, 37)\n",
      "val_images shape: (5846, 150, 150, 3)\n",
      "val_labels shape: (5846, 37)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = validate_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(validate_images.shape))\n",
    "print (\"val_labels shape: \" + str(validate_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13949, 67500)\n",
      "(3478, 67500)\n",
      "(5846, 67500)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = validate_images.reshape(validate_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (13949,1))\n",
    "test_y = np.reshape(test_labels[:,0], (3478,1))\n",
    "val_y = np.reshape(validate_labels[:,0], (5846,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the datasets for later use\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(train_y, open(\"train_stanford_y.pkl\", \"wb\"))\n",
    "pickle.dump(test_y, open(\"test_stanford_y.pkl\", \"wb\"))\n",
    "pickle.dump(val_y, open(\"val_stanford_y.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump(train_img, open(\"train_stanford_img.pkl\", \"wb\"))\n",
    "pickle.dump(test_img, open(\"test_stanford_img.pkl\", \"wb\"))\n",
    "pickle.dump(val_img, open(\"val_stanford_img.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump(train_images, open(\"train_stanford_images.pkl\", \"wb\"))\n",
    "pickle.dump(test_images, open(\"test_stanford_images.pkl\", \"wb\"))\n",
    "pickle.dump(validate_images, open(\"validate_stanford_images.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump(train_labels, open(\"train_stanford_labels.pkl\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"test_stanford_labels.pkl\", \"wb\"))\n",
    "pickle.dump(validate_labels, open(\"val_stanford_labels.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "1422px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
